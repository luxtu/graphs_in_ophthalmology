{
    "parameters": {
        "activation": "relu",
        "aggregation_mode": "add",
        "batch_norm": true,
        "dropout": 0.1,
        "final_layers": 1,
        "hidden_channels": 64,
        "homogeneous_conv": "gcn",
        "num_layers": 1,
        "post_layers": 2,
        "pre_layers": 4
    },
    "split": 1
}

