{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msampling\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'preprocessing'"
     ]
    }
   ],
   "source": [
    "import preprocessing.preprocessing as pp\n",
    "import sampling\n",
    "import random\n",
    "import torch\n",
    "from models import graphClassifier\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "Number of Nodes: 1861\n",
      "Number of Edges: 2413\n",
      "Number of Connected Components: 14\n",
      "Number of Self Loops: 9\n",
      "Number of Isolated Nodes: 0\n",
      "Average Node Degree: 2.5932294465341212\n",
      "***************\n",
      "***************\n",
      "Number of Nodes: 2152\n",
      "Number of Edges: 2710\n",
      "Number of Connected Components: 33\n",
      "Number of Self Loops: 3\n",
      "Number of Isolated Nodes: 0\n",
      "Average Node Degree: 2.5185873605947955\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nodesFileNerve =  \"~/Documents/Intestine/nerve-mask/nodes_nerve_bs2_fh.csv\"\n",
    "edgesFileNerve = \"~/Documents/Intestine/nerve-mask/edges_nerve_bs2_fh.csv\"\n",
    "\n",
    "nodesFileLymph =  \"~/Documents/Intestine/lymph-mask/nodes_lymph_bs2_fh.csv\"\n",
    "edgesFileLymph = \"~/Documents/Intestine/lymph-mask/edges_lymph_bs2_fh.csv\"\n",
    "\n",
    "nodes_n = pd.read_csv(nodesFileNerve, sep = \";\", index_col= \"id\")\n",
    "edges_n = pd.read_csv(edgesFileNerve, sep = \";\", index_col= \"id\")\n",
    "nodes_l = pd.read_csv(nodesFileLymph, sep = \";\", index_col= \"id\")\n",
    "edges_l = pd.read_csv(edgesFileLymph, sep = \";\", index_col= \"id\")\n",
    "\n",
    "\n",
    "# scaling with the factors provided by luciano\n",
    "nodes_l = pp.scale_position(nodes_l, (1.65,1.65,6))\n",
    "nodes_n = pp.scale_position(nodes_n, (1.65,1.65,6))\n",
    "\n",
    "# create the graphs for both networks\n",
    "G_nerve = pp.create_graph(nodes_n, edges_n, index_addon =\"n\")\n",
    "G_lymph = pp.create_graph(nodes_l, edges_l, index_addon =\"l\")\n",
    "\n",
    "# get short description of graph\n",
    "pp.graph_summary(G_nerve)\n",
    "pp.graph_summary(G_lymph)\n",
    "\n",
    "# get rid of self-loops, multi edges and isolated nodes\n",
    "G_nerve_einf = pp.to_einfach(G_nerve)\n",
    "G_lymph_einf = pp.to_einfach(G_lymph)\n",
    "\n",
    "# enrich the attributes of the nodes with information from the incident edges\n",
    "pp.enrich_node_attrs(G_lymph_einf)\n",
    "pp.enrich_node_attrs(G_nerve_einf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Classification using Subsets of Lymph and Nerve Network for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating subgraphs using random node neighbor selection.: 100%|██████████| 100/100 [00:00<00:00, 375.15it/s]\n",
      "Creating subgraphs using random node neighbor selection.: 100%|██████████| 100/100 [00:00<00:00, 516.26it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph_node_num = 100\n",
    "\n",
    "# create random samples \n",
    "randomSampleLymphNx, randomSampleLymph = sampling.randomGeomSubgraphs(G_lymph_einf, label = 1,starts = 100, node_sample_size = graph_node_num,  mode = \"rnn\")\n",
    "randomSampleNerveNx, randomSampleNerve = sampling.randomGeomSubgraphs(G_nerve_einf, label = 0,starts = 100, node_sample_size = graph_node_num,  mode = \"rnn\")\n",
    "\n",
    "# combine the graphs to a random set\n",
    "allGraphs = randomSampleLymph + randomSampleNerve\n",
    "random.shuffle(allGraphs)\n",
    "\n",
    "# split into training and test set\n",
    "breaker = int(len(allGraphs)*0.8)\n",
    "train_dataset = allGraphs[:breaker]\n",
    "test_dataset = allGraphs[breaker:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.5166, Test Acc: 0.4737\n",
      "Epoch: 002, Train Acc: 0.5166, Test Acc: 0.4737\n",
      "Epoch: 003, Train Acc: 0.5166, Test Acc: 0.4737\n",
      "Epoch: 004, Train Acc: 0.5430, Test Acc: 0.4737\n",
      "Epoch: 005, Train Acc: 0.5828, Test Acc: 0.5000\n",
      "Epoch: 006, Train Acc: 0.6623, Test Acc: 0.5526\n",
      "Epoch: 007, Train Acc: 0.5563, Test Acc: 0.4737\n",
      "Epoch: 008, Train Acc: 0.5298, Test Acc: 0.4737\n",
      "Epoch: 009, Train Acc: 0.7351, Test Acc: 0.8421\n",
      "Epoch: 010, Train Acc: 0.8079, Test Acc: 0.7368\n",
      "Epoch: 011, Train Acc: 0.5695, Test Acc: 0.4737\n",
      "Epoch: 012, Train Acc: 0.7285, Test Acc: 0.5789\n",
      "Epoch: 013, Train Acc: 0.8212, Test Acc: 0.8158\n",
      "Epoch: 014, Train Acc: 0.8146, Test Acc: 0.8158\n",
      "Epoch: 015, Train Acc: 0.8146, Test Acc: 0.7632\n",
      "Epoch: 016, Train Acc: 0.8146, Test Acc: 0.7632\n",
      "Epoch: 017, Train Acc: 0.8079, Test Acc: 0.7632\n",
      "Epoch: 018, Train Acc: 0.8212, Test Acc: 0.8158\n",
      "Epoch: 019, Train Acc: 0.8212, Test Acc: 0.7632\n",
      "Epoch: 020, Train Acc: 0.7682, Test Acc: 0.6053\n",
      "Epoch: 021, Train Acc: 0.8146, Test Acc: 0.8421\n",
      "Epoch: 022, Train Acc: 0.7815, Test Acc: 0.7105\n",
      "Epoch: 023, Train Acc: 0.8278, Test Acc: 0.7632\n",
      "Epoch: 024, Train Acc: 0.8146, Test Acc: 0.7895\n",
      "Epoch: 025, Train Acc: 0.8013, Test Acc: 0.7632\n",
      "Epoch: 026, Train Acc: 0.8411, Test Acc: 0.7632\n",
      "Epoch: 027, Train Acc: 0.8212, Test Acc: 0.7632\n",
      "Epoch: 028, Train Acc: 0.8278, Test Acc: 0.7632\n",
      "Epoch: 029, Train Acc: 0.7947, Test Acc: 0.7632\n",
      "Epoch: 030, Train Acc: 0.8278, Test Acc: 0.7895\n",
      "Epoch: 031, Train Acc: 0.8278, Test Acc: 0.7632\n",
      "Epoch: 032, Train Acc: 0.8278, Test Acc: 0.7895\n",
      "Epoch: 033, Train Acc: 0.8212, Test Acc: 0.7632\n",
      "Epoch: 034, Train Acc: 0.8278, Test Acc: 0.7632\n",
      "Epoch: 035, Train Acc: 0.8146, Test Acc: 0.7632\n",
      "Epoch: 036, Train Acc: 0.8278, Test Acc: 0.7632\n",
      "Epoch: 037, Train Acc: 0.8212, Test Acc: 0.7632\n",
      "Epoch: 038, Train Acc: 0.8278, Test Acc: 0.7632\n",
      "Epoch: 039, Train Acc: 0.8278, Test Acc: 0.7632\n",
      "Epoch: 040, Train Acc: 0.8278, Test Acc: 0.7632\n",
      "Epoch: 041, Train Acc: 0.8344, Test Acc: 0.7632\n",
      "Epoch: 042, Train Acc: 0.8278, Test Acc: 0.7895\n",
      "Epoch: 043, Train Acc: 0.8477, Test Acc: 0.7632\n",
      "Epoch: 044, Train Acc: 0.8278, Test Acc: 0.7895\n",
      "Epoch: 045, Train Acc: 0.8278, Test Acc: 0.8421\n",
      "Epoch: 046, Train Acc: 0.7947, Test Acc: 0.7632\n",
      "Epoch: 047, Train Acc: 0.8344, Test Acc: 0.8421\n",
      "Epoch: 048, Train Acc: 0.8146, Test Acc: 0.8421\n",
      "Epoch: 049, Train Acc: 0.8013, Test Acc: 0.7895\n",
      "Epoch: 050, Train Acc: 0.8278, Test Acc: 0.7895\n"
     ]
    }
   ],
   "source": [
    "# selection of the features to use\n",
    "feat_slice = [1,3,7,8]\n",
    "\n",
    "# create the model\n",
    "model = graphClassifier.GCN_GC(hidden_channels=32, in_features = len(feat_slice), classes = 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# create brach data loaders for training and test set\n",
    "train_loader = DataLoader(train_dataset, batch_size= 64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "def train_GC():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "         out = model(data.x[:,feat_slice], data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "         loss = criterion(out, data.y)  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "\n",
    "\n",
    "def test_GC(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         out = model(data.x[:,feat_slice], data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    train_GC()\n",
    "    train_acc = test_GC(train_loader)\n",
    "    test_acc = test_GC(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
